// webppl test/wppl/game/train_model_seqL1.wppl --require ../lib/webppl-nn --require ../gameppl --require . --random-seed 1 --rootDir . --uttF L_utt --obsF L_obs --outputF L_out --iterations 100 --latentDim 50 --splitName game_34_33_33 --splitType GAME_ROUND --sIterations 100

var args = util_parseArgs();
var rootDir = args["rootDir"];
var uttFName = args["uttF"];
var obsFName = args["obsF"]
var outputFName = args["outputF"];
var iterations = args["iterations"]*1;
var sIterations = args["sIterations"]*1;
var latentDim = args["latentDim"]*1;
var splitName = args["splitName"];
var splitType = args["splitType"];
var evalSamples = args["evalSamples"]*1;
var incSamples = args["incSamples"]*1;
var qualSamples = args["qualSamples"]*1;
var rsaAlpha = 1.0;
var maxUtteranceLength = 5;
var s0sampleSize = 5;
var batchSize = 10; //100;
var gradientSamples = 1;
var approximationBeamSize = 5;

display("Loading feature matrices...");

var uttf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + uttFName);
var obsf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + obsFName);
var outputf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + outputFName);

var uttF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + uttFName);
var obsF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + obsFName);
var outputF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + outputFName);

display("Constructing data set...");

var D = data_makeUttObsFromFeatureMatrices(uttF, obsF, outputF, { uttType : DATA_TYPE_SCALAR_SEQUENCE, obsType : DATA_TYPE_VECTOR, outputType : DATA_TYPE_SCALAR, maxInputSequenceLength: maxUtteranceLength });
var partition = gameppl.partition.load(rootDir + "/examples/games/splits/" + splitName);
var splitFn = (splitType === "GAME") ? gameppl.data.getDatumGame : (splitType === "ROUND") ? gameppl.data.getDatumRound : gameppl.data.getDatumGameRound

var D_split = gameppl.partition.split(partition, D, splitFn);
var D_train = D_split['train'];
var D_dev = D_split['dev'];

var utteranceDimension = gameppl.feature.getFeatureMatrixVocabularySize(uttF);
var s0inputDimension = 3;
var meaningInputDimension = 3 + utteranceDimension;

display("(Vocabulary size: " + utteranceDimension + ")");

var rsaObservedWorldFn = function(input) {
    var obs = input.observation;
    var H0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_0");
    var S0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_0");
    var L0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_0");

    var H1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_1");
    var S1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_1");
    var L1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_1");

    var H2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_2");
    var S2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_2");
    var L2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_2");

    var hsl0 = Vector([H0, S0, L0]);
    var hsl1 = Vector([H1, S1, L1]);
    var hsl2 = Vector([H2, S2, L2]);

    return [hsl0, hsl1, hsl2];
};

var s0inputFn = function(observation, hidden) { return observation[hidden]; };

var makeS0ContextDatum = function(datum) {
    var new_d = mapObject(function (key, value) {
        if (key === 'input')
            return { observation : rsaObservedWorldFn(value), hidden : datum.output }
        else if (key == 'output')
            return datum.input.utterance
        else
            return value
        }, datum);
    return new_d;
};

var l1model = l1seqSampling_initTrainedModel({
    maxUtteranceLength : maxUtteranceLength,
    utteranceDimension : utteranceDimension,
    meaningInputDimension : meaningInputDimension,
    s0inputDimension : s0inputDimension,
    latentDimension : latentDim,
    s0sampleSize : s0sampleSize,
    iterations : iterations,
    sIterations : sIterations,
    gradientSamples : gradientSamples,
    batchSize : batchSize,
    beamSize : approximationBeamSize,
    // Hidden is index... indexes into observation
    meaningSeqFn: function(utterance, hidden, observation) {
        var hiddenColor = observation[hidden];
        var uttWorld = map(function(x) {
            concat([oneHot(x, utteranceDimension), hiddenColor])
        }, utterance);
        return uttWorld;
    },
    s0inputFn: s0inputFn,
    rsaAlpha: rsaAlpha,
    rsaObservedWorldFn: rsaObservedWorldFn,
    rsaUtteranceFn: function(input) {
        return input.utterance;
    },
    // Draw a color index
    rsaWorldPrior: function(observed) {
        return uniformDraw([0, 1, 2]);
    }
}, D_train);

display("Training language model for incremental evaluation");
var D_S0_train = map(makeS0ContextDatum, D_train);
var D_S0_dev = map(makeS0ContextDatum, D_dev);

var s_model = s_initTrainedModel({
    maxUtteranceLength : maxUtteranceLength,
    utteranceDimension : utteranceDimension,
    latentDimension : latentDim,
    beamSize : approximationBeamSize,
    iterations : sIterations,
    gradientSamples : gradientSamples,
    batchSize : batchSize }, D_S0_train);

display("Finished training... outputting example predictions.");

color_data_displayExamplesL(D_dev, obsf, uttf, qualSamples, l1model, l1seqSampling_getDistributionFn(l1model));

display("Evaluating accuracy...");

var trainEval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l1model, gameppl.util._first(D_train, evalSamples), l1seqSampling_getDistributionFn(l1model)), "l1.train");
var devEval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l1model, gameppl.util._first(D_dev, evalSamples), l1seqSampling_getDistributionFn(l1model)), "l1.dev");

display("Evaluating l0 accuracy...");

var l0distFn = l1seqSampling_getL0DistributionFn(l1model);
var trainL0Eval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l1model, gameppl.util._first(D_train, evalSamples), l0distFn), "l0.train");
var devL0Eval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l1model, gameppl.util._first(D_dev, evalSamples), l0distFn), "l0.dev");

display("Evaluating incremental...");

var meaningFn = l1seqSampling_getMeaningFn(l1model); // utterance x hidden x observation -> [0, 1]
var makeScoreFn = function(datum) {
    return function (utterance) {
        return meaningFn(utterance, datum.input.hidden, datum.input.observation);
    };
};
var devIncEval = evaluation_modelEncEvalFlattened(evaluation_modelMeaningExpectedIncrement(makeScoreFn, gameppl.util._first(D_S0_dev, incSamples), s_model), "dev");
var trainIncEval = evaluation_modelEncEvalFlattened(evaluation_modelMeaningExpectedIncrement(makeScoreFn, gameppl.util._first(D_S0_train, incSamples), s_model), "train");

var keysValues = evaluation_flattenedKeyValueStrings([trainEval, devEval, trainL0Eval, devL0Eval, trainIncEval, devIncEval]);

display("F\tseed\titerations\t" + keysValues[0]);
display(obsFName + "\t" + args["random-seed"] + "\t" + iterations + "\t" + keysValues[1]);
