// Run with:
// webppl test/wppl/game/train_model_seqL0.wppl --require ../lib/webppl-nn --require ../gameppl --require . --random-seed 1 --rootDir . --uttF L_utt --obsF L_obs --outputF L_out --iterations 100 --latentDim 50 --splitName game_34_33_33 --splitType GAME_ROUND --sIterations 100

var args = util_parseArgs();
var rootDir = args["rootDir"];
var uttFName = args["uttF"];
var obsFName = args["obsF"]
var outputFName = args["outputF"];
var iterations = args["iterations"]*1;
var latentDim = args["latentDim"]*1;
var splitName = args["splitName"];
var splitType = args["splitType"];
var sIterations = args["sIterations"]*1;
var evalSamples = args["evalSamples"]*1;
var incSamples = args["incSamples"]*1;
var qualSamples = args["qualSamples"]*1;
var rsaAlpha = 1.0;
var maxUtteranceLength = 5;
var batchSize = 10; //100;
var gradientSamples = 1;
var approximationBeamSize = 5;

display("Loading feature matrices...");

var uttf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + uttFName);
var obsf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + obsFName);
var outputf = gameppl.feature.loadFeatureSet(rootDir + "/examples/features/vocab/" + outputFName);

var uttF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + uttFName);
var obsF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + obsFName);
var outputF = gameppl.feature.loadFeatureMatrix(rootDir + "/examples/features/mat/" + outputFName);

display("Constructing data set...");

var D = data_makeUttObsFromFeatureMatrices(uttF, obsF, outputF, { uttType : DATA_TYPE_SCALAR_SEQUENCE, obsType : DATA_TYPE_VECTOR, outputType : DATA_TYPE_SCALAR, maxInputSequenceLength : maxUtteranceLength  });
var partition = gameppl.partition.load(rootDir + "/examples/games/splits/" + splitName);
var splitFn = (splitType === "GAME") ? gameppl.data.getDatumGame : (splitType === "ROUND") ? gameppl.data.getDatumRound : gameppl.data.getDatumGameRound

var D_split = gameppl.partition.split(partition, D, splitFn);
var D_train = D_split['train'];
var D_dev = D_split['dev'];

var utteranceDimension = gameppl.feature.getFeatureMatrixVocabularySize(uttF);
var inputDimension = 3 + utteranceDimension;

display("(Vocabulary size: " + utteranceDimension + ")");

var rsaObservedWorldFn = function(input) {
    var obs = input.observation;
    var H0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_0");
    var S0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_0");
    var L0 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_0");

    var H1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_1");
    var S1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_1");
    var L1 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_1");

    var H2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lH_2");
    var S2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lS_2");
    var L2 = gameppl.feature.getTensorFeatureRangeStart(obs, obsf, "lL_2");

    var hsl0 = Vector([H0, S0, L0]);
    var hsl1 = Vector([H1, S1, L1]);
    var hsl2 = Vector([H2, S2, L2]);

    return [hsl0, hsl1, hsl2];
};

var l0model = l0seq_initTrainedModel({
    utteranceDimension : utteranceDimension,
    inputDimension : inputDimension,
    latentDimension : latentDim,
    iterations : iterations,
    gradientSamples : gradientSamples,
    batchSize : batchSize,
    // Hidden is index... indexes into observation
    seqFn: function(utterance, hidden, observation) {
        var hiddenColor = observation[hidden];
        var uttWorld = map(function(x) {
            concat([oneHot(x, utteranceDimension), hiddenColor])
        }, utterance);
        return uttWorld;
    },
    // Draw a color index
    rsaWorldPrior: function(observed) {
        return uniformDraw([0, 1, 2]);
    },
    // Observed is array containing a vector for each color
    rsaObservedWorldFn: rsaObservedWorldFn,
    rsaUtteranceFn: function(input) {
        return input.utterance;
    }
}, D_train);

display("Training language model for incremental evaluation");
var s0inputFn = function(observation, hidden) { return observation[hidden]; };

var makeS0ContextDatum = function(datum) {
    var new_d = mapObject(function (key, value) {
        if (key === 'input')
            return { observation : rsaObservedWorldFn(value), hidden : datum.output }
        else if (key == 'output')
            return datum.input.utterance
        else
            return value
    }, datum);
    return new_d;
};

var D_S0_train = map(makeS0ContextDatum, D_train);
var D_S0_dev = map(makeS0ContextDatum, D_dev);

var s_model = s_initTrainedModel({
    maxUtteranceLength : maxUtteranceLength,
    utteranceDimension : utteranceDimension,
    latentDimension : latentDim,
    beamSize : approximationBeamSize,
    iterations : sIterations,
    gradientSamples : gradientSamples,
    batchSize : batchSize }, D_S0_train);

display("Finished training... outputting example predictions.");

color_data_displayExamplesL(D_dev, obsf, uttf, qualSamples, l0model, l0seq_getDistributionFn(l0model));

display("Evaluating L0 accuracy");

var trainEval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l0model, gameppl.util._first(D_train, evalSamples), l0seq_getDistributionFn(l0model)), "l0.train");
var devEval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l0model, gameppl.util._first(D_dev, evalSamples), l0seq_getDistributionFn(l0model)), "l0.dev");

display("Evaluating L1 accuracy...");

var l1dist = l0seq_initL1DistributionFn(l0model, {
    s0inputFn: s0inputFn,
    rsaAlpha: rsaAlpha,
    s0sampleSize: 5,
    s0inputDimension: 3,
    iterations: iterations,
    gradientSamples: gradientSamples,
    batchSize: batchSize,
    approximationBeamSize: 5,
    maxUtteranceLength: maxUtteranceLength
}, D_train);

var trainL1Eval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l0model, gameppl.util._first(D_train, evalSamples), l1dist), "l1.train");
var devL1Eval = evaluation_modelEncEvalFlattened(evaluation_modelEncModeAccuracy(l0model, gameppl.util._first(D_dev, evalSamples), l1dist), "l1.dev");

display("Evaluating incremental...");

var meaningFn = l0seq_getMeaningFn(l0model); // utterance x hidden x observation -> [0, 1]
var makeScoreFn = function(datum) {
    return function (utterance) {
        return meaningFn(utterance, datum.input.hidden, datum.input.observation);
    };
};
var devIncEval = evaluation_modelEncEvalFlattened(evaluation_modelMeaningExpectedIncrement(makeScoreFn, gameppl.util._first(D_S0_dev, incSamples), s_model), "dev");
var trainIncEval = evaluation_modelEncEvalFlattened(evaluation_modelMeaningExpectedIncrement(makeScoreFn, gameppl.util._first(D_S0_train, incSamples), s_model), "train");

var keysValues = evaluation_flattenedKeyValueStrings([trainEval, devEval, trainL1Eval, devL1Eval, trainIncEval, devIncEval]);

display("F\tseed\titerations\t" + keysValues[0]);
display(obsFName + "\t" + args["random-seed"] + "\t" + iterations + "\t" + keysValues[1]);
